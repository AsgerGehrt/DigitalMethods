{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping controversies script 8: Explore revision timelines and geographical location of anonymous users\n",
    "\n",
    "The first time you run the script, the aim is to make a timeline over the entire period of the Wikipedia page.\n",
    "You can use this timeline to identify interesting spikes, which may then be used to narrow in your search in order to output a more specific time period when you run the script again. \n",
    "\n",
    "- Step 1: Installing the libraries\n",
    "- Step 2: Load the data\n",
    "- Step 3: Make a timeline of user revisions\n",
    "- Step 4: Make a timeline of unique users making revisions\n",
    "- Step 5:\n",
    "- Step 5: Output the most active users with their stats\n",
    "- Step 6: Review the \"Talk\" page to see what the revision users are talking about"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Installing the right libraries\n",
    "Libraries for Jupyter can be understood as preprogrammed script parts. This means, that instead of writing a lot of lines of code in order e.g. make contact to Wikipedia, you can do it in one command.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "try: #First, Jupyter tries to import a library\n",
    "    import matplotlib\n",
    "    print(\"matplotlib library has been imported\")\n",
    "except: #If it fails, it will try to install the library\n",
    "    print(\"matplotlib library not found. Installing...\")\n",
    "    !pip install matplotlib\n",
    "    try:#... and try to import it again\n",
    "        import matplotlib\n",
    "    except: #unless it fails, and raises an error.\n",
    "        print(\"Something went wrong in the installation of the matplotlib library. Please check your internet connection and consult output from the installation below\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load your data\n",
    "\n",
    "In order to run the script, click on the cell below and press \"Run\" in the menu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import datetime\n",
    "\n",
    "\n",
    "print(\"Enter the name of the page revision json file you wish to explore further (e.g.: MC_script_7_revisions_circumcision_from_2001-01-01_to_now_all) \")\n",
    "print(\"\")\n",
    "filename= input()\n",
    "print(\" \")\n",
    "\n",
    "print(\"READ THIS!: You can now choose to narrow down the period of exploration or keep the original interval contained in the revision json file. If this is the first time you run the script, you should keep the original interval. You cannot go beyond the interval of the json file...\")\n",
    "\n",
    "print(\"Do you wan't to narrow down the period of exploration (y/n)?\")\n",
    "narrow=input()\n",
    "if narrow.lower()==\"y\":\n",
    "    print(\"What is the new start date (yyyy-mm-dd)?\")\n",
    "    start_date_input=input()\n",
    "    print(\"What is the new end date (yyyy-mm-dd)?\")\n",
    "    end_date_input=input()\n",
    "    \n",
    "if not narrow:\n",
    "    narrow=\"n\"\n",
    "if not filename.endswith(\".json\"):\n",
    "    path=filename+\".json\"\n",
    "else: \n",
    "    path=filename\n",
    "    filename=filename.split(\".\")[0]\n",
    "    \n",
    "with open(path) as jsonfile:\n",
    "    revisions = json.load(jsonfile)\n",
    "\n",
    "dict_of_years={}\n",
    "if narrow.lower()==\"n\":\n",
    "    start_date=filename.split(\"from_\")[1].split(\"_\")[0]\n",
    "    start_year=int(start_date.split(\"-\")[0])\n",
    "    end_year=\"2020\"\n",
    "    end_month=(str(datetime.datetime.now()).split(\"-\")[1])\n",
    "    end_date=end_year+\"-\"+end_month+\"-01\"\n",
    "    start_month=(start_date.split(\"-\")[1])\n",
    "if narrow.lower()==\"y\":\n",
    "    start_date=start_date_input\n",
    "    start_year=int(start_date.split(\"-\")[0])\n",
    "    start_month=(start_date.split(\"-\")[1])\n",
    "    end_date=end_date_input\n",
    "    end_year=int(end_date.split(\"-\")[0])\n",
    "    end_month=(end_date.split(\"-\")[1])\n",
    "years=[]\n",
    "for each in range(start_year,int(end_year)+1):\n",
    "    years.append(str(each))\n",
    "    \n",
    "months=['01', '02','03','04','05','06','07','08','09','10','11','12']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for year in years:\n",
    "\n",
    "    dict_of_years[year]={}\n",
    "    if year==str(start_year):\n",
    "        for month in months[months.index(str(start_month)):]:\n",
    "            dict_of_years[year][month]={\"users\":[]}\n",
    "    elif year==str(end_year):\n",
    "        for month in months[:months.index(str(end_month))]:\n",
    "            dict_of_years[year][month]={\"users\":[]}\n",
    "    else: \n",
    "        for month in months:\n",
    "            dict_of_years[year][month]={\"users\":[]}\n",
    "\n",
    "\n",
    "user_ids=[]\n",
    "for revision in revisions:\n",
    "    timestamp=revision[\"timestamp\"]\n",
    "    user_id=revision[\"userid\"]\n",
    "    user_ids.append(user_id)\n",
    "    year=timestamp.split('-')[0]\n",
    "    month=timestamp.split('-')[1]\n",
    "    if year not in years:\n",
    "        continue\n",
    "    if month not in dict_of_years[year]:\n",
    "        continue\n",
    "    \n",
    "    dict_of_years[year][month][\"users\"].append(user_id)\n",
    "locale=!pwd\n",
    "print(\"The data has been loaded. Continue to step 3, 4 or 5\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Make a simple timeline of user revisions\n",
    "OBS: The timeline will be based on the interval you chose in step 2!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Define how you wan't to count the data (year or month)\")\n",
    "input_count=input()\n",
    "if input_count:\n",
    "    count_type=input_count\n",
    "else:\n",
    "    count_type=\"month\"\n",
    "print(\"What would you like to call the timeline?\")\n",
    "timeline_name=input()\n",
    "timeline_name=timeline_name+\"_\"+start_date+\"_\"+end_date+\"_UserRevisions.png\"\n",
    "print(\"Making timeline..\")\n",
    "time_list=[]\n",
    "revisions_list=[]\n",
    "if count_type.lower()==\"month\":\n",
    "    for year in dict_of_years:\n",
    "        for month in dict_of_years[year]:\n",
    "            time_list.append(year+\"-\"+month)\n",
    "            revisions_list.append(len(dict_of_years[year][month][\"users\"]))#, len(set(dict_of_years[year][month][\"users\"])),page ]\n",
    "if count_type.lower()==\"year\":\n",
    "    for year in dict_of_years:\n",
    "        users=[]\n",
    "        \n",
    "        for month in dict_of_years[year]:\n",
    "            users=users+dict_of_years[year][month][\"users\"]\n",
    "        revisions_list.append(len(users))\n",
    "        time_list.append(year)\n",
    "\n",
    "            \n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(len(time_list)*0.30,14*len(time_list)*0.007))\n",
    "ax = plt.axes()\n",
    "ax.plot(time_list, revisions_list);\n",
    "fig.suptitle(\"Number of revisions\", fontsize=round(60*len(time_list)*0.009))\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "fig.set\n",
    "fig.savefig(timeline_name, dpi=100)\n",
    "\n",
    "print(\"Your timeline has been saved. Look in the folder of this script\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Make a simple timeline of unique users making revisions\n",
    "OBS: The timeline will be based on the interval you chose in step 2!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Define how you wan't to count the data (year or month)\")\n",
    "input_count=input()\n",
    "if input_count:\n",
    "    count_type=input_count\n",
    "else:\n",
    "    count_type=\"month\"\n",
    "print(\"What would you like to call the timeline?\")\n",
    "timeline_name=input()\n",
    "timeline_name=timeline_name+\"_\"+start_date+\"_\"+end_date+\"_UniqueUsersRevising.png\"\n",
    "print(\"Making timeline..\")\n",
    "time_list=[]\n",
    "revisions_list=[]\n",
    "if count_type.lower()==\"month\":\n",
    "    for year in dict_of_years:\n",
    "        for month in dict_of_years[year]:\n",
    "            time_list.append(year+\"-\"+month)\n",
    "            revisions_list.append(len(set(dict_of_years[year][month][\"users\"])))#, len(set(dict_of_years[year][month][\"users\"])),page ]\n",
    "if count_type.lower()==\"year\":\n",
    "    for year in dict_of_years:\n",
    "        users=[]\n",
    "        \n",
    "        for month in dict_of_years[year]:\n",
    "            users=users+dict_of_years[year][month][\"users\"]\n",
    "        revisions_list.append(len(set(users)))\n",
    "        time_list.append(year)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "fig = plt.figure(figsize=(len(time_list)*0.30,14*len(time_list)*0.007))\n",
    "ax = plt.axes()\n",
    "ax.plot(time_list, revisions_list);\n",
    "fig.autofmt_xdate()\n",
    "fig.suptitle(\"Number of unique users making revisions\", fontsize=round(60*len(time_list)*0.009))\n",
    "fig.set\n",
    "fig.savefig(timeline_name, dpi=100)\n",
    "print(\"Your timeline has been saved. Look in the folder of this script\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Output the most active users with their stats:\n",
    "OBS: The output will be based on the interval you chose in step 2!\n",
    "Stats include: Number of revisions, groups they are part of, gender (if entered) and if they have been blocked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import requests\n",
    "\n",
    "print(\"How many users to you wan't information on (max 50)?\")\n",
    "user_count=input()\n",
    "if int(user_count)>50:\n",
    "    user_count=50\n",
    "    print(\"You have asked for too many user stats. Lowering to 50..\")\n",
    "print(\"What would you like to call your file?\")\n",
    "input_name=input()\n",
    "csv_path=\"Top_\"+str(user_count)+\"_most_active_users_\"+input_name+\".csv\"\n",
    "user_dict={}\n",
    "cnt=Counter(user_ids)\n",
    "mc=cnt.most_common(50)\n",
    "usr_list=[]\n",
    "for user in mc:\n",
    "    user_dict[user[0]]={\"revisions_in_set\":user[1]}\n",
    "    usr_list.append(user[0])\n",
    "long_user=''\n",
    "\n",
    "for user in usr_list:\n",
    "    if str(user)!=\"0\":\n",
    "        if not usr_list.index(user)==len(usr_list)-1:\n",
    "            long_user=long_user+str(user)+'|'\n",
    "        else:\n",
    "            long_user=long_user+str(user)\n",
    "\n",
    "S = requests.Session()\n",
    "\n",
    "URL = \"https://en.wikipedia.org/w/api.php\"\n",
    "\n",
    "PARAMS = {\n",
    "    \"action\": \"query\",\n",
    "    \"format\": \"json\",\n",
    "    \"list\": \"users\",\n",
    "    \"ususerids\": long_user,\n",
    "    \"usprop\": \"groups|editcount|registration|gender|blockinfo\"\n",
    "}\n",
    "\n",
    "R = S.get(url=URL, params=PARAMS)\n",
    "DATA = R.json()\n",
    "\n",
    "csv_headers=[\"user_id\", \"user_name\", \"groups\", \"gender\", \"edit_count_total\", \"edit_count_current_page\", \"registration_date\"]\n",
    "with open(csv_path,\"w\", newline='',encoding='utf-8') as f:\n",
    "    wr = csv.writer(f, delimiter=\",\")\n",
    "    wr.writerow(csv_headers)\n",
    "for each in DATA[\"query\"][\"users\"]:\n",
    "    user_dict[each[\"userid\"]][\"edit_count\"]=each[\"editcount\"]\n",
    "    user_dict[each[\"userid\"]][\"registration\"]=each[\"registration\"]\n",
    "    user_dict[each[\"userid\"]][\"groups\"]=each[\"groups\"]\n",
    "    user_dict[each[\"userid\"]][\"gender\"]=each[\"gender\"]\n",
    "    user_dict[each[\"userid\"]][\"name\"]=each[\"name\"]\n",
    "    csv_list=[each[\"userid\"],each[\"name\"],each[\"groups\"],each[\"gender\"],each[\"editcount\"],user_dict[each[\"userid\"]][\"revisions_in_set\"],each[\"registration\"]]\n",
    "    with open(csv_path,\"a\", newline='',encoding='utf-8') as f:\n",
    "        wr = csv.writer(f, delimiter=\",\")\n",
    "        wr.writerow(csv_list)\n",
    "print(\"Your file has been saved in the same folder as this script is running from. \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Review the \"Talk\" page to see what the revision users are talking about.\n",
    "The Talk page of a wikipedia page is where the users discuss and argue about changes and revisions. You can see an example [here](https://en.wikipedia.org/wiki/Talk:Circumcision/). If you open the csv file with all the revisions (e.g. MCTutorial4_revisions_circumcision_from_2001-01-01_to_now_all.csv), you might notice that the users often refer to the \"Talk\" page in their comments to revisions. We can review the talk pages, to get a better understanding of what is at stake!\n",
    "In order to limit the amount of \"Talk\" we need to review, you can enter a start and end date, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "print(\"What page do you want to harvest Talk from?\")\n",
    "page_name=input()\n",
    "print(\"\")\n",
    "print(\"Please be careful aout choosing a long interval, as it might take a while to collect the data. Recommended interval is 1 month.\")\n",
    "print(\"Enter the start date for Talk on \"+page_name+\" (yyyy-mm-dd):\")\n",
    "start_date=input()\n",
    "print(\"Enter the end date for Talk on \"+page_name+\" (yyyy-mm-dd):\")\n",
    "end_date=input()\n",
    "\n",
    "#print(\"Do you want do limit to top \"+str(user_count)+\" users (y/n)?\")\n",
    "#top=input()\n",
    "top=\"n\"\n",
    "S = requests.Session()\n",
    "\n",
    "\n",
    "URL = \"https://wikipedia.org/w/api.php\"\n",
    "ok=1\n",
    "page_name_under=page_name.replace(\" \", \"_\")\n",
    "if top.lower()==\"n\":\n",
    "    PARAMS = {\n",
    "        \"action\": \"query\",\n",
    "        \"prop\": \"revisions\",\n",
    "        \"titles\": \"talk:\"+page_name,\n",
    "        \"rvprop\": \"timestamp|ids\",\n",
    "        \"rvslots\": \"main\",\n",
    "        \"rvdir\": \"newer\",\n",
    "        \"rvlimit\":\"500\",\n",
    "        \"rvstart\": start_date+\"T00:00:00Z\",\n",
    "        \"rvend\":end_date+\"T00:00:00Z\",\n",
    "        \"formatversion\": \"2\",\n",
    "        \"format\": \"json\"\n",
    "    }\n",
    "    rev_ids=[]\n",
    "    R = S.get(url=URL, params=PARAMS)\n",
    "    DATA = R.json()\n",
    "    for page in DATA[\"query\"][\"pages\"]:\n",
    "        if \"revisions\" in page:\n",
    "            for each in page[\"revisions\"]:\n",
    "                rev_id=each[\"revid\"]\n",
    "                rev_ids.append(rev_id)    \n",
    "    while 'continue' in DATA.keys() and ok:\n",
    "        PARAMS = {\n",
    "            \"action\": \"query\",\n",
    "            \"prop\": \"revisions\",\n",
    "            \"titles\": \"talk:\"+page_name,\n",
    "            \"rvlimit\": \"500\",\n",
    "            \"rvprop\": \"timestamp|user|ids\",\n",
    "            \"rvdir\": \"newer\",\n",
    "            \"rvstart\": start_date+\"T00:00:00Z\",\n",
    "            \"rvend\":end_date+\"T00:00:00Z\",\n",
    "            \"formatversion\": \"2\",\n",
    "            \"format\": \"json\",\n",
    "            \"rvcontinue\": DATA['continue']['rvcontinue']\n",
    "\n",
    "        }\n",
    "\n",
    "\n",
    "        R = S.get(url=URL, params=PARAMS)\n",
    "        DATA = R.json()\n",
    "        for page in DATA['query']['pages']:\n",
    "            for each in page[\"revisions\"]:\n",
    "                rev_id=each[\"revid\"]\n",
    "                rev_ids.append(rev_id)\n",
    "if len(set(rev_ids))==0:\n",
    "    print(\"The script harvested \"+str(len(set(rev_ids)))+\" unique talks. Try another interval\")\n",
    "else:\n",
    "    print(\"The script harvested \"+str(len(set(rev_ids)))+\" unique talks.\")\n",
    "csv_path=\"Talk_from_\"+page_name+\"_from_\"+start_date+\"_to_\"+end_date+\".csv\"\n",
    "\n",
    "csv_headers=[\"Talk id\", \"Talk url\", \"page name\"]\n",
    "with open(csv_path,\"w\", newline='',encoding='utf-8') as f:\n",
    "    wr = csv.writer(f, delimiter=\",\")\n",
    "    wr.writerow(csv_headers)\n",
    "for each in list(set(rev_ids)):\n",
    "    url_=\"https://en.wikipedia.org/w/index.php?title=Talk:\"+page_name_under+\"&oldid=\"+str(each)\n",
    "    \n",
    "    csv_list=[each, url_, page_name_under]\n",
    "    with open(csv_path,\"a\", newline='',encoding='utf-8') as f:\n",
    "        wr = csv.writer(f, delimiter=\",\")\n",
    "        wr.writerow(csv_list)\n",
    "        \n",
    "print(\"Script is done. You can find your file in the folder.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
