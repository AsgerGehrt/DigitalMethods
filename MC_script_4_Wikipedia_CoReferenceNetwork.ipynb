{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping controversies script 3: Making a co-reference network from category members  \n",
    "\n",
    "A co-reference network is based on pages' shared references. This means, that an edge will be made between two pages, if they share the same reference. That edge will become stronger, if the two pages share more references. \n",
    "This script only looks at references that are listed under the section \"References\", and not all the links to other Wikipedia articles found throughout the text. For a script that handles the latter, please consult tutorial 3. \n",
    "\n",
    "<img src=\"https://res.cloudinary.com/dra3btd6p/image/upload/v1549394296/Mapping%20controversies%202019/Circumcision_references.jpg\" title=\"Category:circumcision\" style=\"width: 800px;\" /> \n",
    "\n",
    "The network outputted from the script is an __undirected__ network, and will look somewhat like this in structure:\n",
    "\n",
    "<img src=\"https://res.cloudinary.com/dra3btd6p/image/upload/v1549628658/Mapping%20controversies%202019/CoRefNet.jpg\" title=\"Category:circumcision\" style=\"width: 800px;\" /> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Installing the right libraries\n",
    "Libraries for Jupyter can be understood as preprogrammed script parts. This means, that instead of writing a lot of lines of code in order e.g. make contact to Wikipedia, you can do it in one command.\n",
    "\n",
    "__Obs: in this workbook we will be using the wikipedia and networkx libraries. If you have already installed them once, there is no need to do it again. You may simply skip to step 2.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this cell Jupyter checks whether you have the right libraries installed \n",
    "\n",
    "try: #First, Jupyter tries to import a library\n",
    "    import wikipedia\n",
    "    print(\"Wikipedia library has been imported\")\n",
    "except: #If it fails, it will try to install the library\n",
    "    print(\"Wikipedia library not found. Installing...\")\n",
    "    !pip install wikipedia\n",
    "    try:#... and try to import it again\n",
    "        import wikipedia\n",
    "    except: #unless it fails, and raises an error.\n",
    "        print(\"Something went wrong in the installation of the wikipedia library. Please check your internet connection and consult output from the installation below\")\n",
    "try:\n",
    "    import networkx\n",
    "    print(\"NetworkX library has been imported\")\n",
    "except:\n",
    "    print(\"NetworkX library not found. Installing...\")\n",
    "    !pip install networkx\n",
    "    \n",
    "    try:\n",
    "        import networkx\n",
    "    except:\n",
    "        print(\"Something went wrong in the installation of the NetworkX library. Please check your internet connection and consult output from the installation below\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Make the network\n",
    "\n",
    "The next step is to make the network. Here, you need to input the path to the json files you got from the MCTutorial2_2_Wikipedia_HarvestCatMembers_final script. \n",
    "\n",
    "If the JSON files are in the same directory as the scripts, you only need to input relational directions (i.e. the name of the json file e.g. cat_members_circumcision_depth_2)\n",
    "\n",
    "<img src=\"https://res.cloudinary.com/dra3btd6p/image/upload/v1549436096/Mapping%20controversies%202019/Script_json_same_folder.jpg\" title=\"Folder\" style=\"width: 800px;\" /> \n",
    "\n",
    "In order to run the script, click on the cell below and press \"Run\" in the menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import wikipedia\n",
    "import networkx as nx\n",
    "import csv\n",
    "\n",
    "cat_members_all=[]\n",
    "print(\"Enter the name of the category members json file you wish to use for keyword search (e.g.cat_members_circumcision_depth_2). If you have multiple files separate them with a comma\")\n",
    "filename= input()\n",
    "if \",\" in filename:\n",
    "\n",
    "    for each in filename.split(\",\"):\n",
    "\n",
    "\n",
    "        if not each.endswith(\".json\"):\n",
    "            path=each+\".json\"\n",
    "        else: \n",
    "            path=each\n",
    "            each=each.split(\".\")[0]\n",
    "        with open(path) as jsonfile:\n",
    "            cat_members = json.load(jsonfile)\n",
    "            jsonfile.close()\n",
    "        for every in cat_members:\n",
    "            cat_members_all.append(every)\n",
    "else:\n",
    "    print(\" \")\n",
    "\n",
    "\n",
    "    if not filename.endswith(\".json\"):\n",
    "        path=filename+\".json\"\n",
    "    else: \n",
    "        path=filename\n",
    "        filename=filename.split(\".\")[0]\n",
    "    with open(path) as jsonfile:\n",
    "        cat_members_all = json.load(jsonfile)\n",
    "        jsonfile.close()\n",
    "\n",
    "    \n",
    "edges = []\n",
    "\n",
    "cat_members_dict={}\n",
    "cat_members_list=[]\n",
    "for cat_member in cat_members_all:\n",
    "    title=cat_member[\"title\"]\n",
    "    \n",
    "    try:\n",
    "        page = wikipedia.page(title)\n",
    "    except wikipedia.exceptions.DisambiguationError:\n",
    "        print(\"Wikipedia thinks \"+title+\" is ambiguous (returns several candidate pages). Trying again with all capitalized letters\")\n",
    "        try:\n",
    "            page = wikipedia.page(title.capitalize())\n",
    "            print(\"Success! \"+title+\" is no longer ambiguous\")\n",
    "        except wikipedia.exceptions.DisambiguationError:\n",
    "            print(\"Wikipedia still thinks \"+title+\" is ambiguous (returns several candidate pages). Trying again with all lower letters\")\n",
    "            try:\n",
    "                page = wikipedia.page(title.lower())\n",
    "                print(\"Success! \"+title+\" is no longer ambiguous\")\n",
    "            except wikipedia.exceptions.DisambiguationError:\n",
    "                print(\"Wikipedia still thinks \"+title+\" is ambiguous (returns several candidate pages). Skipping page...\")\n",
    "                continue\n",
    "    except wikipedia.exceptions.PageError:\n",
    "        print(\"The page \"+title+\" could not be found. Skipping page...\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    try:\n",
    "        refs = page.references\n",
    "      #  print(target_refs)\n",
    "        cat_members_dict[title]={\"level\":cat_member[\"level\"], \"references\":refs}\n",
    "        cat_members_list.append(title)\n",
    "\n",
    "    except KeyError:\n",
    "        print(\"Could not retrieve references for \"+title+\". Skipping page...\")\n",
    "        continue\n",
    "print(\"Succesfully retrieved references from \"+str(len(cat_members_dict))+\" out of \"+str(len(cat_members_all))+\" wikipedia pages. Generating network....\")\n",
    "\n",
    "for i,source in enumerate(cat_members_list):\n",
    "    source_refs = cat_members_dict[source][\"references\"]\n",
    "    if len(source_refs)>0:\n",
    "        for target in cat_members_list[i+1:]:\n",
    "            if target==source:\n",
    "                continue\n",
    "            target_refs=cat_members_dict[target][\"references\"]\n",
    "            if len(target_refs)>0:\n",
    "                overlap = len(set(source_refs).intersection(target_refs))\n",
    "                if overlap>0:\n",
    "                    if len(source_refs) < len(target_refs):\n",
    "                        norm_overlap_by_smallest = overlap / len(source_refs)\n",
    "                    else:\n",
    "                        norm_overlap_by_smallest = overlap / len(target_refs)\n",
    "                    edge = (source,target,{'overlap':overlap,'norm_overlap_by_smallest':norm_overlap_by_smallest})\n",
    "                    edges.append(edge)\n",
    "print(\"Network has been generated. Saving...\")\n",
    "G = nx.Graph()\n",
    "G.add_edges_from(edges)\n",
    "nx.write_gexf(G, 'MCTutorial2_4_'+filename+'_CoReferenceNetwork.gexf')\n",
    "print('Network saved. You can find the network by following this path: ')\n",
    "locale=!pwd\n",
    "print(locale[0]+\"/\"+'MCTutorial2_4_'+filename+\"_CoReferenceNetwork.gexf\")\n",
    "print(\"\")\n",
    "print(\"Saving JSON file with all references...\")\n",
    "json_path='MCTutorial2_4_'+filename+\"_references.json\"\n",
    "\n",
    "with open(json_path, 'w') as outfile:\n",
    "    json.dump(cat_members_dict, outfile)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Saving CSV file with all references...\")\n",
    "print(\"\")\n",
    "\n",
    "headers=['Page_title','Reference']\n",
    "csv_path='MCTutorial2_4_'+filename+\"_references.csv\"\n",
    "\n",
    "with open(csv_path,\"w\", newline='',encoding='utf-8') as f:\n",
    "    wr = csv.writer(f, delimiter=\",\")\n",
    "    wr.writerow(headers)\n",
    "    \n",
    "for cat_member in cat_members_list:\n",
    "    cat_member_ref=cat_members_dict[cat_member][\"references\"]\n",
    "    for ref in cat_member_ref:\n",
    "        csv_list=[cat_member, ref]\n",
    "        with open(csv_path,\"a\", newline='',encoding='utf-8') as f:\n",
    "            wr = csv.writer(f, delimiter=\",\")\n",
    "            wr.writerow(csv_list)\n",
    "\n",
    "print(\"CSV file saved. The script is done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
